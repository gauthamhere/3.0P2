{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GauthamK_Phase2_Assignment2LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauthamhere/3.0P2/blob/master/GauthamK_Phase2_Assignment2LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt3N9fogsXaZ",
        "colab_type": "code",
        "outputId": "bc0b7f30-1083-4b98-e193-b427234a7135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from shutil import copyfile\n",
        "import keras.utils\n",
        "import keras.backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import LSTM,Input,Dense,Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eit1xODmri28",
        "colab_type": "code",
        "outputId": "db6b6431-a283-44e4-d9be-c23ede0125fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgthnWuXrmx9",
        "colab_type": "code",
        "outputId": "b24e97fb-4b86-407f-9327-eebb9a3bfd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "copyfile(\"gdrive/My Drive/lstm_assignment/wonderland.txt\",'wonderland.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wonderland.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHAMvMnrsrz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_characters(source, length=None, limit=None,):\n",
        "    \n",
        "    # Reading raw text from source and destination files\n",
        "    f = open(source, 'r')\n",
        "    x_data = f.read()\n",
        "    f.close()\n",
        "\n",
        "    print('raw data read')\n",
        "    \n",
        "    x_data = x_data.lower()\n",
        "    \n",
        "    #Removing punctutations\n",
        "    puncts = string.punctuation\n",
        "    x_data = str(x_data)\n",
        "    for punct in puncts:\n",
        "      if punct in x_data:\n",
        "        x_data = x_data.replace(punct, '')\n",
        "\n",
        "    if limit is not None:\n",
        "        x_data = x_data[:limit]\n",
        "\n",
        "    # Splitting raw text into array of sequences\n",
        "    if length is None:\n",
        "        x = [list(line) for line in x_data.split('\\n') if len(line) > 0]\n",
        "    else:\n",
        "        x = [list(chunk) for chunk in chunks(x_data, length)]\n",
        "\n",
        "    # Creating the vocabulary set with the most common characters (leaving room for PAD, START, UNK)\n",
        "    chars = set()\n",
        "    for line in x:\n",
        "        for char in line:\n",
        "            chars.add(char)\n",
        "\n",
        "    # Creating an array of words from the vocabulary set, we will use this array as index-to-word dictionary\n",
        "    i2c = list(chars)\n",
        "\n",
        "    # Creating the word-to-index dictionary from the array created above\n",
        "    c2i = {word:ix for ix, word in enumerate(i2c)}\n",
        "\n",
        "    # Converting each word to its index value\n",
        "    for i, sentence in enumerate(x):\n",
        "        for j, word in enumerate(sentence):\n",
        "            if word in c2i:\n",
        "                x[i][j] = c2i[word]\n",
        "            else:\n",
        "                x[i][j] = c2i['<UNK>']\n",
        "\n",
        "    return x, c2i, i2c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwu_YOYAqYVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Sample an index from a probability vector\n",
        "    :param preds:\n",
        "    :param temperature:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(preds)\n",
        "\n",
        "    preds = np.log(preds) / temperature\n",
        "\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "    return np.argmax(probas)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfBio5jqCh6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunks(l, n):\n",
        "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk64U5Ror2Fn",
        "colab_type": "code",
        "outputId": "fbe2e59a-3709-4217-aa2b-549529a23d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, char_to_ix, ix_to_char = load_characters('wonderland.txt',length=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw data read\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgUbwo-4tOTr",
        "colab_type": "code",
        "outputId": "3c92cee1-0efe-41e7-ad09-ed470591fca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_max_len = max([len(sentence) for sentence in x])\n",
        "numchars = len(ix_to_char)\n",
        "print(numchars, ' distinct characters found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28  distinct characters found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRgcAyOKthob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = sequence.pad_sequences(x, x_max_len, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ8OXczptiji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(seq):\n",
        "        return ''.join(ix_to_char[id] for id in seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVVPiDNJtp0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = x.shape[0]\n",
        "\n",
        "x_in  = np.concatenate([np.ones((n, 1)), x[:, :-1]], axis=1)  \n",
        "x_out = x\n",
        "assert x_in.shape == x_out.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvwVLfYouKUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_categorical(batch, num_classes):\n",
        "    \n",
        "    b, l = batch.shape\n",
        "\n",
        "    out = np.zeros((b, l, num_classes))\n",
        "\n",
        "    for i in range(b):\n",
        "        seq = batch[0, :]\n",
        "        out[i, :, :] = keras.utils.to_categorical(seq, num_classes=num_classes)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Y8oXx4t1WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  convert from integer sequences to sequences of one-hot vectors\n",
        "x_in = to_categorical(x_in, numchars)\n",
        "x_out =to_categorical(x_out, numchars)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXgKQcDMw7dA",
        "colab_type": "code",
        "outputId": "5f8577a2-d0c3-413c-9f8b-522fe8e8e83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "input = Input(shape=(None, numchars))\n",
        "h = LSTM(256,dropout =0.1, return_sequences=True)(input)\n",
        "h = Dropout(0.1)(h)\n",
        "h = LSTM(256, return_sequences=True)(h)\n",
        "out = Dense(numchars, activation='softmax')(h)\n",
        "model = Model(input, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 05:04:30.543606 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 05:04:30.585454 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 05:04:30.594274 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 05:04:30.803979 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0727 05:04:30.815769 140572291811200 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sWyx1Wruyno",
        "colab_type": "code",
        "outputId": "9af26d68-cb15-41c9-9434-39b7581c1770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, 28)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 256)         291840    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 256)         525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 28)          7196      \n",
            "=================================================================\n",
            "Total params: 824,348\n",
            "Trainable params: 824,348\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRHaouUsyDO9",
        "colab_type": "code",
        "outputId": "a609cfb4-07ca-43e1-b518-4fc9b6577eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 05:04:31.441850 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 05:04:31.468287 140572291811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayFUxHtFqLnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_seq(model : Model,seed,numchars,size,temperature=1.0):\n",
        "    \n",
        "    ls = seed.shape[0]\n",
        "\n",
        "    tokens = np.concatenate([seed, np.zeros(size - ls)])\n",
        "\n",
        "    # convert the integer sequence to a categorical one\n",
        "    toh = to_categorical(tokens[None, :], numchars)\n",
        "\n",
        "    for i in range(ls, size-1):\n",
        "\n",
        "        # predict next characters (for the whole sequence)\n",
        "        probs = model.predict(toh)\n",
        "\n",
        "        # Extract the i-th probability vector and sample an index from it\n",
        "        next_token = sample(probs[0, i-1, :], temperature)\n",
        "\n",
        "        tokens[i] = next_token\n",
        "\n",
        "        # update the one-hot encoding\n",
        "        toh[0, i, 0] = 0\n",
        "        toh[0, i, next_token] = 1\n",
        "\n",
        "    return [int(t) for t in tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlKaMWzRnIFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHECK = 5\n",
        "gen_length = 100\n",
        "out_every = 25 #Generate output for every 5 epochs\n",
        "\n",
        "def generate(epoch):\n",
        "        if epoch % out_every == 0 and epoch > 0:\n",
        "            for i in range(CHECK):\n",
        "                b = random.randint(0, n - 1)\n",
        "\n",
        "                seed = x[b, :20]\n",
        "                seed = np.insert(seed, 0, 1)\n",
        "                gen = generate_seq(model, seed, numchars, gen_length)\n",
        "\n",
        "                print('Seed:', decode(seed), '\\n\\nGenerated text:', decode(gen[len(seed):]))\n",
        "                print()\n",
        "\n",
        "    # Train the model\n",
        "generate_stuff = keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: generate(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTOroHTx4mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"gdrive/My Drive/lstm_assignment/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint,generate_stuff]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii6Bv8ZMymrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwHM9_bXzB7W",
        "colab_type": "code",
        "outputId": "8ae848c9-6f06-4a8d-b1b3-63c92b4dc5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training for 100 epochs\n",
        "model.fit(x_in, x_out, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 05:04:31.671421 140572291811200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1401/1401 [==============================] - 6s 4ms/step - loss: 3.3067\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.30672, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-01-3.3067-bigger.hdf5\n",
            "Epoch 2/100\n",
            "1401/1401 [==============================] - 1s 572us/step - loss: 3.0917\n",
            "\n",
            "Epoch 00002: loss improved from 3.30672 to 3.09174, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-02-3.0917-bigger.hdf5\n",
            "Epoch 3/100\n",
            "1401/1401 [==============================] - 1s 558us/step - loss: 2.8409\n",
            "\n",
            "Epoch 00003: loss improved from 3.09174 to 2.84093, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-03-2.8409-bigger.hdf5\n",
            "Epoch 4/100\n",
            "1401/1401 [==============================] - 1s 565us/step - loss: 2.7574\n",
            "\n",
            "Epoch 00004: loss improved from 2.84093 to 2.75744, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-04-2.7574-bigger.hdf5\n",
            "Epoch 5/100\n",
            "1401/1401 [==============================] - 1s 574us/step - loss: 2.7113\n",
            "\n",
            "Epoch 00005: loss improved from 2.75744 to 2.71129, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-05-2.7113-bigger.hdf5\n",
            "Epoch 6/100\n",
            "1401/1401 [==============================] - 1s 562us/step - loss: 2.6891\n",
            "\n",
            "Epoch 00006: loss improved from 2.71129 to 2.68912, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-06-2.6891-bigger.hdf5\n",
            "Epoch 7/100\n",
            "1401/1401 [==============================] - 1s 562us/step - loss: 2.6808\n",
            "\n",
            "Epoch 00007: loss improved from 2.68912 to 2.68076, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-07-2.6808-bigger.hdf5\n",
            "Epoch 8/100\n",
            "1401/1401 [==============================] - 1s 560us/step - loss: 2.6588\n",
            "\n",
            "Epoch 00008: loss improved from 2.68076 to 2.65877, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-08-2.6588-bigger.hdf5\n",
            "Epoch 9/100\n",
            "1401/1401 [==============================] - 1s 567us/step - loss: 2.6280\n",
            "\n",
            "Epoch 00009: loss improved from 2.65877 to 2.62795, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-09-2.6280-bigger.hdf5\n",
            "Epoch 10/100\n",
            "1401/1401 [==============================] - 1s 621us/step - loss: 2.5830\n",
            "\n",
            "Epoch 00010: loss improved from 2.62795 to 2.58298, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-10-2.5830-bigger.hdf5\n",
            "Epoch 11/100\n",
            "1401/1401 [==============================] - 1s 580us/step - loss: 2.5186\n",
            "\n",
            "Epoch 00011: loss improved from 2.58298 to 2.51864, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-11-2.5186-bigger.hdf5\n",
            "Epoch 12/100\n",
            "1401/1401 [==============================] - 1s 587us/step - loss: 2.4469\n",
            "\n",
            "Epoch 00012: loss improved from 2.51864 to 2.44688, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-12-2.4469-bigger.hdf5\n",
            "Epoch 13/100\n",
            "1401/1401 [==============================] - 1s 633us/step - loss: 2.3647\n",
            "\n",
            "Epoch 00013: loss improved from 2.44688 to 2.36474, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-13-2.3647-bigger.hdf5\n",
            "Epoch 14/100\n",
            "1401/1401 [==============================] - 1s 618us/step - loss: 2.3046\n",
            "\n",
            "Epoch 00014: loss improved from 2.36474 to 2.30461, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-14-2.3046-bigger.hdf5\n",
            "Epoch 15/100\n",
            "1401/1401 [==============================] - 1s 588us/step - loss: 2.2219\n",
            "\n",
            "Epoch 00015: loss improved from 2.30461 to 2.22189, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-15-2.2219-bigger.hdf5\n",
            "Epoch 16/100\n",
            "1401/1401 [==============================] - 1s 624us/step - loss: 2.1766\n",
            "\n",
            "Epoch 00016: loss improved from 2.22189 to 2.17660, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-16-2.1766-bigger.hdf5\n",
            "Epoch 17/100\n",
            "1401/1401 [==============================] - 1s 602us/step - loss: 2.0886\n",
            "\n",
            "Epoch 00017: loss improved from 2.17660 to 2.08856, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-17-2.0886-bigger.hdf5\n",
            "Epoch 18/100\n",
            "1401/1401 [==============================] - 1s 607us/step - loss: 2.0053\n",
            "\n",
            "Epoch 00018: loss improved from 2.08856 to 2.00526, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-18-2.0053-bigger.hdf5\n",
            "Epoch 19/100\n",
            "1401/1401 [==============================] - 1s 578us/step - loss: 1.9296\n",
            "\n",
            "Epoch 00019: loss improved from 2.00526 to 1.92957, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-19-1.9296-bigger.hdf5\n",
            "Epoch 20/100\n",
            "1401/1401 [==============================] - 1s 559us/step - loss: 1.9100\n",
            "\n",
            "Epoch 00020: loss improved from 1.92957 to 1.91004, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-20-1.9100-bigger.hdf5\n",
            "Epoch 21/100\n",
            "1401/1401 [==============================] - 1s 587us/step - loss: 1.8371\n",
            "\n",
            "Epoch 00021: loss improved from 1.91004 to 1.83709, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-21-1.8371-bigger.hdf5\n",
            "Epoch 22/100\n",
            "1401/1401 [==============================] - 1s 619us/step - loss: 1.7602\n",
            "\n",
            "Epoch 00022: loss improved from 1.83709 to 1.76015, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-22-1.7602-bigger.hdf5\n",
            "Epoch 23/100\n",
            "1401/1401 [==============================] - 1s 576us/step - loss: 1.6827\n",
            "\n",
            "Epoch 00023: loss improved from 1.76015 to 1.68274, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-23-1.6827-bigger.hdf5\n",
            "Epoch 24/100\n",
            "1401/1401 [==============================] - 1s 638us/step - loss: 1.6283\n",
            "\n",
            "Epoch 00024: loss improved from 1.68274 to 1.62834, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-24-1.6283-bigger.hdf5\n",
            "Epoch 25/100\n",
            "1401/1401 [==============================] - 1s 576us/step - loss: 1.5651\n",
            "\n",
            "Epoch 00025: loss improved from 1.62834 to 1.56511, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-25-1.5651-bigger.hdf5\n",
            "Epoch 26/100\n",
            "1401/1401 [==============================] - 1s 598us/step - loss: 1.5096\n",
            "\n",
            "Epoch 00026: loss improved from 1.56511 to 1.50958, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-26-1.5096-bigger.hdf5\n",
            "Seed: bnder what latitude\n",
            "o \n",
            "\n",
            "Generated text: gnoggee eeeyerete o  oi tttgng   y  sseii\n",
            "tt\n",
            "n\n",
            "trb enenndd    oofhava n nightgk\n",
            "\n",
            "Seed: bnd it it occurred to \n",
            "\n",
            "Generated text:  g  o tteee yy ireedsif ttntngyyy rrssstrn tethne anhanaan of fi vg noghongitek\n",
            "\n",
            "Seed: by savage exclaimed a \n",
            "\n",
            "Generated text: nggntoggt tvtyyittroiof  f itiiib  yb essssseetooeheh  kaa an df  vivn nhotignk\n",
            "\n",
            "Seed: be said alice very lo \n",
            "\n",
            "Generated text: ti goe g eer vwtid f iiittt byeerirrssrioo\n",
            "anbtkrhakk kak nodanaaa  nnggohhiggk\n",
            "\n",
            "Seed: b beautiful soup\n",
            "\n",
            "    \n",
            "\n",
            "Generated text: gto g t vyyrriddf idsittig  y  yri strr ooe nthee hnkn dnn oo ovnnih oo  ho tek\n",
            "\n",
            "Epoch 27/100\n",
            "1401/1401 [==============================] - 1s 560us/step - loss: 1.4723\n",
            "\n",
            "Epoch 00027: loss improved from 1.50958 to 1.47228, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-27-1.4723-bigger.hdf5\n",
            "Epoch 28/100\n",
            "1401/1401 [==============================] - 1s 574us/step - loss: 1.4312\n",
            "\n",
            "Epoch 00028: loss improved from 1.47228 to 1.43123, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-28-1.4312-bigger.hdf5\n",
            "Epoch 29/100\n",
            "1401/1401 [==============================] - 1s 558us/step - loss: 1.3679\n",
            "\n",
            "Epoch 00029: loss improved from 1.43123 to 1.36785, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-29-1.3679-bigger.hdf5\n",
            "Epoch 30/100\n",
            "1401/1401 [==============================] - 1s 637us/step - loss: 1.3123\n",
            "\n",
            "Epoch 00030: loss improved from 1.36785 to 1.31226, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-30-1.3123-bigger.hdf5\n",
            "Epoch 31/100\n",
            "1401/1401 [==============================] - 1s 610us/step - loss: 1.2819\n",
            "\n",
            "Epoch 00031: loss improved from 1.31226 to 1.28191, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-31-1.2819-bigger.hdf5\n",
            "Epoch 32/100\n",
            "1401/1401 [==============================] - 1s 610us/step - loss: 1.2026\n",
            "\n",
            "Epoch 00032: loss improved from 1.28191 to 1.20264, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-32-1.2026-bigger.hdf5\n",
            "Epoch 33/100\n",
            "1401/1401 [==============================] - 1s 599us/step - loss: 1.1890\n",
            "\n",
            "Epoch 00033: loss improved from 1.20264 to 1.18904, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-33-1.1890-bigger.hdf5\n",
            "Epoch 34/100\n",
            "1401/1401 [==============================] - 1s 581us/step - loss: 1.1257\n",
            "\n",
            "Epoch 00034: loss improved from 1.18904 to 1.12566, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-34-1.1257-bigger.hdf5\n",
            "Epoch 35/100\n",
            "1401/1401 [==============================] - 1s 598us/step - loss: 1.2023\n",
            "\n",
            "Epoch 00035: loss did not improve from 1.12566\n",
            "Epoch 36/100\n",
            "1401/1401 [==============================] - 1s 566us/step - loss: 1.1023\n",
            "\n",
            "Epoch 00036: loss improved from 1.12566 to 1.10232, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-36-1.1023-bigger.hdf5\n",
            "Epoch 37/100\n",
            "1401/1401 [==============================] - 1s 551us/step - loss: 1.0653\n",
            "\n",
            "Epoch 00037: loss improved from 1.10232 to 1.06530, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-37-1.0653-bigger.hdf5\n",
            "Epoch 38/100\n",
            "1401/1401 [==============================] - 1s 568us/step - loss: 1.0302\n",
            "\n",
            "Epoch 00038: loss improved from 1.06530 to 1.03025, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-38-1.0302-bigger.hdf5\n",
            "Epoch 39/100\n",
            "1401/1401 [==============================] - 1s 604us/step - loss: 0.9888\n",
            "\n",
            "Epoch 00039: loss improved from 1.03025 to 0.98884, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-39-0.9888-bigger.hdf5\n",
            "Epoch 40/100\n",
            "1401/1401 [==============================] - 1s 613us/step - loss: 0.9484\n",
            "\n",
            "Epoch 00040: loss improved from 0.98884 to 0.94842, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-40-0.9484-bigger.hdf5\n",
            "Epoch 41/100\n",
            "1401/1401 [==============================] - 1s 602us/step - loss: 0.9003\n",
            "\n",
            "Epoch 00041: loss improved from 0.94842 to 0.90033, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-41-0.9003-bigger.hdf5\n",
            "Epoch 42/100\n",
            "1401/1401 [==============================] - 1s 566us/step - loss: 0.8969\n",
            "\n",
            "Epoch 00042: loss improved from 0.90033 to 0.89689, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-42-0.8969-bigger.hdf5\n",
            "Epoch 43/100\n",
            "1401/1401 [==============================] - 1s 597us/step - loss: 0.8347\n",
            "\n",
            "Epoch 00043: loss improved from 0.89689 to 0.83475, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-43-0.8347-bigger.hdf5\n",
            "Epoch 44/100\n",
            "1401/1401 [==============================] - 1s 643us/step - loss: 0.8295\n",
            "\n",
            "Epoch 00044: loss improved from 0.83475 to 0.82953, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-44-0.8295-bigger.hdf5\n",
            "Epoch 45/100\n",
            "1401/1401 [==============================] - 1s 570us/step - loss: 0.9851\n",
            "\n",
            "Epoch 00045: loss did not improve from 0.82953\n",
            "Epoch 46/100\n",
            "1401/1401 [==============================] - 1s 596us/step - loss: 0.8241\n",
            "\n",
            "Epoch 00046: loss improved from 0.82953 to 0.82407, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-46-0.8241-bigger.hdf5\n",
            "Epoch 47/100\n",
            "1401/1401 [==============================] - 1s 589us/step - loss: 0.7984\n",
            "\n",
            "Epoch 00047: loss improved from 0.82407 to 0.79844, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-47-0.7984-bigger.hdf5\n",
            "Epoch 48/100\n",
            "1401/1401 [==============================] - 1s 568us/step - loss: 0.7655\n",
            "\n",
            "Epoch 00048: loss improved from 0.79844 to 0.76549, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-48-0.7655-bigger.hdf5\n",
            "Epoch 49/100\n",
            "1401/1401 [==============================] - 1s 615us/step - loss: 0.7291\n",
            "\n",
            "Epoch 00049: loss improved from 0.76549 to 0.72907, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-49-0.7291-bigger.hdf5\n",
            "Epoch 50/100\n",
            "1401/1401 [==============================] - 1s 596us/step - loss: 0.6962\n",
            "\n",
            "Epoch 00050: loss improved from 0.72907 to 0.69621, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-50-0.6962-bigger.hdf5\n",
            "Epoch 51/100\n",
            "1401/1401 [==============================] - 1s 580us/step - loss: 0.6716\n",
            "\n",
            "Epoch 00051: loss improved from 0.69621 to 0.67156, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-51-0.6716-bigger.hdf5\n",
            "Seed: bhing the king had sa \n",
            "\n",
            "Generated text: ninn  ttotee  ev y tided of iitiig bb herrssitr \n",
            "on tte  ankdanddof hhiinn ohik\n",
            "\n",
            "Seed: bem said the mouse wi \n",
            "\n",
            "Generated text: n g ooog  verrytiird    fitttnn  b hre sisseenont he b ak a d  f vvin  noohin k\n",
            "\n",
            "Seed: b whole window\n",
            "\n",
            "  sur \n",
            "\n",
            "Generated text:   tg evtvrry tie d of stitngg ybhhrr sssteroo   ee kaa aado   aavin noohhhnh tk\n",
            "\n",
            "Seed: bl mad here\n",
            "im mad  y \n",
            "\n",
            "Generated text: t ttggt  ver ttirdedo  ittiing byyh esssttrr\n",
            "oo thenbnk   aaof h aning tonhignk\n",
            "\n",
            "Seed: bou were me\n",
            "\n",
            "  well p \n",
            "\n",
            "Generated text: nn to g t   ey ttrreo of siti n by herrsiitsrron th ebaak  d of haviignnnotin k\n",
            "\n",
            "Epoch 52/100\n",
            "1401/1401 [==============================] - 1s 563us/step - loss: 0.6494\n",
            "\n",
            "Epoch 00052: loss improved from 0.67156 to 0.64943, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-52-0.6494-bigger.hdf5\n",
            "Epoch 53/100\n",
            "1401/1401 [==============================] - 1s 558us/step - loss: 0.6274\n",
            "\n",
            "Epoch 00053: loss improved from 0.64943 to 0.62738, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-53-0.6274-bigger.hdf5\n",
            "Epoch 54/100\n",
            "1401/1401 [==============================] - 1s 562us/step - loss: 0.6016\n",
            "\n",
            "Epoch 00054: loss improved from 0.62738 to 0.60156, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-54-0.6016-bigger.hdf5\n",
            "Epoch 55/100\n",
            "1401/1401 [==============================] - 1s 592us/step - loss: 0.5928\n",
            "\n",
            "Epoch 00055: loss improved from 0.60156 to 0.59285, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-55-0.5928-bigger.hdf5\n",
            "Epoch 56/100\n",
            "1401/1401 [==============================] - 1s 620us/step - loss: 0.5596\n",
            "\n",
            "Epoch 00056: loss improved from 0.59285 to 0.55961, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-56-0.5596-bigger.hdf5\n",
            "Epoch 57/100\n",
            "1401/1401 [==============================] - 1s 568us/step - loss: 0.5509\n",
            "\n",
            "Epoch 00057: loss improved from 0.55961 to 0.55092, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-57-0.5509-bigger.hdf5\n",
            "Epoch 58/100\n",
            "1401/1401 [==============================] - 1s 568us/step - loss: 0.5730\n",
            "\n",
            "Epoch 00058: loss did not improve from 0.55092\n",
            "Epoch 59/100\n",
            "1401/1401 [==============================] - 1s 563us/step - loss: 0.8892\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.55092\n",
            "Epoch 60/100\n",
            "1401/1401 [==============================] - 1s 573us/step - loss: 0.6436\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.55092\n",
            "Epoch 61/100\n",
            "1401/1401 [==============================] - 1s 564us/step - loss: 0.5851\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.55092\n",
            "Epoch 62/100\n",
            "1401/1401 [==============================] - 1s 554us/step - loss: 0.5531\n",
            "\n",
            "Epoch 00062: loss did not improve from 0.55092\n",
            "Epoch 63/100\n",
            "1401/1401 [==============================] - 1s 572us/step - loss: 0.5259\n",
            "\n",
            "Epoch 00063: loss improved from 0.55092 to 0.52588, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-63-0.5259-bigger.hdf5\n",
            "Epoch 64/100\n",
            "1401/1401 [==============================] - 1s 603us/step - loss: 0.4883\n",
            "\n",
            "Epoch 00064: loss improved from 0.52588 to 0.48830, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-64-0.4883-bigger.hdf5\n",
            "Epoch 65/100\n",
            "1401/1401 [==============================] - 1s 605us/step - loss: 0.4695\n",
            "\n",
            "Epoch 00065: loss improved from 0.48830 to 0.46950, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-65-0.4695-bigger.hdf5\n",
            "Epoch 66/100\n",
            "1401/1401 [==============================] - 1s 596us/step - loss: 0.4464\n",
            "\n",
            "Epoch 00066: loss improved from 0.46950 to 0.44642, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-66-0.4464-bigger.hdf5\n",
            "Epoch 67/100\n",
            "1401/1401 [==============================] - 1s 564us/step - loss: 0.4274\n",
            "\n",
            "Epoch 00067: loss improved from 0.44642 to 0.42743, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-67-0.4274-bigger.hdf5\n",
            "Epoch 68/100\n",
            "1401/1401 [==============================] - 1s 616us/step - loss: 0.4132\n",
            "\n",
            "Epoch 00068: loss improved from 0.42743 to 0.41321, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-68-0.4132-bigger.hdf5\n",
            "Epoch 69/100\n",
            "1401/1401 [==============================] - 1s 610us/step - loss: 0.3951\n",
            "\n",
            "Epoch 00069: loss improved from 0.41321 to 0.39507, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-69-0.3951-bigger.hdf5\n",
            "Epoch 70/100\n",
            "1401/1401 [==============================] - 1s 569us/step - loss: 0.3800\n",
            "\n",
            "Epoch 00070: loss improved from 0.39507 to 0.38001, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-70-0.3800-bigger.hdf5\n",
            "Epoch 71/100\n",
            "1401/1401 [==============================] - 1s 587us/step - loss: 0.3654\n",
            "\n",
            "Epoch 00071: loss improved from 0.38001 to 0.36538, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-71-0.3654-bigger.hdf5\n",
            "Epoch 72/100\n",
            "1401/1401 [==============================] - 1s 592us/step - loss: 0.3533\n",
            "\n",
            "Epoch 00072: loss improved from 0.36538 to 0.35328, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-72-0.3533-bigger.hdf5\n",
            "Epoch 73/100\n",
            "1401/1401 [==============================] - 1s 569us/step - loss: 0.3402\n",
            "\n",
            "Epoch 00073: loss improved from 0.35328 to 0.34020, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-73-0.3402-bigger.hdf5\n",
            "Epoch 74/100\n",
            "1401/1401 [==============================] - 1s 583us/step - loss: 0.3285\n",
            "\n",
            "Epoch 00074: loss improved from 0.34020 to 0.32853, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-74-0.3285-bigger.hdf5\n",
            "Epoch 75/100\n",
            "1401/1401 [==============================] - 1s 615us/step - loss: 0.3167\n",
            "\n",
            "Epoch 00075: loss improved from 0.32853 to 0.31669, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-75-0.3167-bigger.hdf5\n",
            "Epoch 76/100\n",
            "1401/1401 [==============================] - 1s 605us/step - loss: 0.3058\n",
            "\n",
            "Epoch 00076: loss improved from 0.31669 to 0.30582, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-76-0.3058-bigger.hdf5\n",
            "Seed: bould break  she piti \n",
            "\n",
            "Generated text: ng to  ete vyyt irrd of ssttingb y h rr isttr\n",
            "onnthe  anak nddof having nothnnk\n",
            "\n",
            "Seed: b  turn that dormouse \n",
            "\n",
            "Generated text: niing to ge t ery tiredoof iitinn by  hr siiier\n",
            "on tte bba kanndoo fhvving nthk\n",
            "\n",
            "Seed: bg so very remarkable \n",
            "\n",
            "Generated text: ino too eee ere tiredd ffsititng by hrr sister\n",
            "o  tee bannnand  f aavving nothk\n",
            "\n",
            "Seed: b am  but id\n",
            "better t \n",
            "\n",
            "Generated text: ngtoo e  veer  rredoo  iitti g  yher ssiter\n",
            "on thh bank an   o haaingg nohhnhgk\n",
            "\n",
            "Seed: b dormouse\n",
            "\n",
            "  write t \n",
            "\n",
            "Generated text: o tget veey tirreo f stttnng y heer sistrron thee bank nn offhhvvin noohhng ttk\n",
            "\n",
            "Epoch 77/100\n",
            "1401/1401 [==============================] - 1s 557us/step - loss: 0.2945\n",
            "\n",
            "Epoch 00077: loss improved from 0.30582 to 0.29452, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-77-0.2945-bigger.hdf5\n",
            "Epoch 78/100\n",
            "1401/1401 [==============================] - 1s 559us/step - loss: 0.2847\n",
            "\n",
            "Epoch 00078: loss improved from 0.29452 to 0.28470, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-78-0.2847-bigger.hdf5\n",
            "Epoch 79/100\n",
            "1401/1401 [==============================] - 1s 566us/step - loss: 0.2755\n",
            "\n",
            "Epoch 00079: loss improved from 0.28470 to 0.27552, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-79-0.2755-bigger.hdf5\n",
            "Epoch 80/100\n",
            "1401/1401 [==============================] - 1s 559us/step - loss: 0.2660\n",
            "\n",
            "Epoch 00080: loss improved from 0.27552 to 0.26596, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-80-0.2660-bigger.hdf5\n",
            "Epoch 81/100\n",
            "1401/1401 [==============================] - 1s 555us/step - loss: 0.2565\n",
            "\n",
            "Epoch 00081: loss improved from 0.26596 to 0.25650, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-81-0.2565-bigger.hdf5\n",
            "Epoch 82/100\n",
            "1401/1401 [==============================] - 1s 587us/step - loss: 0.2489\n",
            "\n",
            "Epoch 00082: loss improved from 0.25650 to 0.24894, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-82-0.2489-bigger.hdf5\n",
            "Epoch 83/100\n",
            "1401/1401 [==============================] - 1s 586us/step - loss: 0.2390\n",
            "\n",
            "Epoch 00083: loss improved from 0.24894 to 0.23896, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-83-0.2390-bigger.hdf5\n",
            "Epoch 84/100\n",
            "1401/1401 [==============================] - 1s 560us/step - loss: 0.2310\n",
            "\n",
            "Epoch 00084: loss improved from 0.23896 to 0.23102, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-84-0.2310-bigger.hdf5\n",
            "Epoch 85/100\n",
            "1401/1401 [==============================] - 1s 560us/step - loss: 0.2231\n",
            "\n",
            "Epoch 00085: loss improved from 0.23102 to 0.22314, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-85-0.2231-bigger.hdf5\n",
            "Epoch 86/100\n",
            "1401/1401 [==============================] - 1s 551us/step - loss: 0.2165\n",
            "\n",
            "Epoch 00086: loss improved from 0.22314 to 0.21651, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-86-0.2165-bigger.hdf5\n",
            "Epoch 87/100\n",
            "1401/1401 [==============================] - 1s 562us/step - loss: 0.2080\n",
            "\n",
            "Epoch 00087: loss improved from 0.21651 to 0.20799, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-87-0.2080-bigger.hdf5\n",
            "Epoch 88/100\n",
            "1401/1401 [==============================] - 1s 561us/step - loss: 0.2009\n",
            "\n",
            "Epoch 00088: loss improved from 0.20799 to 0.20088, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-88-0.2009-bigger.hdf5\n",
            "Epoch 89/100\n",
            "1401/1401 [==============================] - 1s 591us/step - loss: 0.1950\n",
            "\n",
            "Epoch 00089: loss improved from 0.20088 to 0.19502, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-89-0.1950-bigger.hdf5\n",
            "Epoch 90/100\n",
            "1401/1401 [==============================] - 1s 592us/step - loss: 0.1877\n",
            "\n",
            "Epoch 00090: loss improved from 0.19502 to 0.18769, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-90-0.1877-bigger.hdf5\n",
            "Epoch 91/100\n",
            "1401/1401 [==============================] - 1s 631us/step - loss: 0.1821\n",
            "\n",
            "Epoch 00091: loss improved from 0.18769 to 0.18213, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-91-0.1821-bigger.hdf5\n",
            "Epoch 92/100\n",
            "1401/1401 [==============================] - 1s 583us/step - loss: 0.1753\n",
            "\n",
            "Epoch 00092: loss improved from 0.18213 to 0.17528, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-92-0.1753-bigger.hdf5\n",
            "Epoch 93/100\n",
            "1401/1401 [==============================] - 1s 563us/step - loss: 0.1693\n",
            "\n",
            "Epoch 00093: loss improved from 0.17528 to 0.16928, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-93-0.1693-bigger.hdf5\n",
            "Epoch 94/100\n",
            "1401/1401 [==============================] - 1s 577us/step - loss: 0.1628\n",
            "\n",
            "Epoch 00094: loss improved from 0.16928 to 0.16284, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-94-0.1628-bigger.hdf5\n",
            "Epoch 95/100\n",
            "1401/1401 [==============================] - 1s 631us/step - loss: 0.1568\n",
            "\n",
            "Epoch 00095: loss improved from 0.16284 to 0.15684, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-95-0.1568-bigger.hdf5\n",
            "Epoch 96/100\n",
            "1401/1401 [==============================] - 1s 627us/step - loss: 0.1526\n",
            "\n",
            "Epoch 00096: loss improved from 0.15684 to 0.15261, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-96-0.1526-bigger.hdf5\n",
            "Epoch 97/100\n",
            "1401/1401 [==============================] - 1s 572us/step - loss: 0.1457\n",
            "\n",
            "Epoch 00097: loss improved from 0.15261 to 0.14571, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-97-0.1457-bigger.hdf5\n",
            "Epoch 98/100\n",
            "1401/1401 [==============================] - 1s 573us/step - loss: 0.1414\n",
            "\n",
            "Epoch 00098: loss improved from 0.14571 to 0.14140, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-98-0.1414-bigger.hdf5\n",
            "Epoch 99/100\n",
            "1401/1401 [==============================] - 1s 649us/step - loss: 0.1363\n",
            "\n",
            "Epoch 00099: loss improved from 0.14140 to 0.13626, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-99-0.1363-bigger.hdf5\n",
            "Epoch 100/100\n",
            "1401/1401 [==============================] - 1s 639us/step - loss: 0.1322\n",
            "\n",
            "Epoch 00100: loss improved from 0.13626 to 0.13224, saving model to gdrive/My Drive/lstm_assignment/weights-improvement-100-0.1322-bigger.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd93b3ba0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Nj9fpjWyZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"gdrive/My Drive/lstm_assignment/weights-improvement-100-0.1322-bigger.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4fQ9U_JDWXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "d9f92646-2a4f-4161-eb48-ff1816cb2f4d"
      },
      "source": [
        "gen_length=500  #Predicting 500 characters\n",
        "\n",
        "b = random.randint(0, n - 1)\n",
        "seed = x[b, :40]\n",
        "seed = np.insert(seed, 0, 1)\n",
        "  \n",
        "gen = generate_seq(model,seed, numchars, gen_length)\n",
        "\n",
        "print('Seed:', decode(seed), '\\n\\nGenerated text:', decode(gen[len(seed):]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: bhen she noticed a\n",
            "curious appearance in  \n",
            "\n",
            "Generated text: dofisitinn byhher siitrr\n",
            "on  he bankk nd fo hvving nothing tttttvey  iirdd f fiittingbby her iister\n",
            "\n",
            "n the baana nd of having nothnng ttt tvvrytiiredoof iittnng y  her isiee\n",
            "\n",
            "o  the bnn aan  of haiing nohhing ttttt  r  tirrd of iitting by her siste\n",
            "\n",
            "on the bank andoof having nothin  tttt verytirdd  f ssittnng by her ssseer\n",
            "nn the aank and ofhhvvigg ooting ttttt vey tiied  of sitting by her sister\n",
            "ontthe bank and oo having  tthing tttttveyr iireddofssittik\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0J9mkJ2D0lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}